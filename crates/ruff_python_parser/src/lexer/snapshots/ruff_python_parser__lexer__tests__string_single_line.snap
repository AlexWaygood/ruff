---
source: crates/ruff_python_parser/src/lexer/mod.rs
expression: tokens
---
[
    Token {
        kind: String,
        length: 8,
        value: Some(
            "\"double\"",
        ),
        flags: TokenFlags(
            0x0,
        ),
    },
    Token {
        kind: Whitespace,
        length: 1,
        value: None,
        flags: TokenFlags(
            0x0,
        ),
    },
    Token {
        kind: String,
        length: 8,
        value: Some(
            "'single'",
        ),
        flags: TokenFlags(
            0x0,
        ),
    },
    Token {
        kind: Whitespace,
        length: 1,
        value: None,
        flags: TokenFlags(
            0x0,
        ),
    },
    Token {
        kind: String,
        length: 8,
        value: Some(
            "'can\\'t'",
        ),
        flags: TokenFlags(
            0x0,
        ),
    },
    Token {
        kind: Whitespace,
        length: 1,
        value: None,
        flags: TokenFlags(
            0x0,
        ),
    },
    Token {
        kind: String,
        length: 6,
        value: Some(
            "\"\\\\\\\"\"",
        ),
        flags: TokenFlags(
            0x0,
        ),
    },
    Token {
        kind: Whitespace,
        length: 1,
        value: None,
        flags: TokenFlags(
            0x0,
        ),
    },
    Token {
        kind: String,
        length: 8,
        value: Some(
            "'\\t\\r\\n'",
        ),
        flags: TokenFlags(
            0x0,
        ),
    },
    Token {
        kind: Whitespace,
        length: 1,
        value: None,
        flags: TokenFlags(
            0x0,
        ),
    },
    Token {
        kind: String,
        length: 4,
        value: Some(
            "'\\g'",
        ),
        flags: TokenFlags(
            0x0,
        ),
    },
    Token {
        kind: Whitespace,
        length: 1,
        value: None,
        flags: TokenFlags(
            0x0,
        ),
    },
    Token {
        kind: String,
        length: 8,
        value: Some(
            "r'raw\\''",
        ),
        flags: TokenFlags(
            Raw,
        ),
    },
    Token {
        kind: Whitespace,
        length: 1,
        value: None,
        flags: TokenFlags(
            0x0,
        ),
    },
    Token {
        kind: String,
        length: 6,
        value: Some(
            "'\\420'",
        ),
        flags: TokenFlags(
            0x0,
        ),
    },
    Token {
        kind: Whitespace,
        length: 1,
        value: None,
        flags: TokenFlags(
            0x0,
        ),
    },
    Token {
        kind: String,
        length: 9,
        value: Some(
            "'\\200\\0a'",
        ),
        flags: TokenFlags(
            0x0,
        ),
    },
    Token {
        kind: EndOfFile,
        length: 0,
        value: None,
        flags: TokenFlags(
            0x0,
        ),
    },
]
